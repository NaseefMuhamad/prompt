{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abba84ba",
   "metadata": {},
   "source": [
    "## ALMUZAHIM NASEEF MUHAMAD S24B38/006 B30296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d887705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032d7e9",
   "metadata": {},
   "source": [
    "i used a dotenv so that my key cannot get exposed on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99f003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3be2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your messages. Type 'bye' to exit.\n",
      "\n",
      "Gemini: Reply skipped due to word count limits.\n",
      "\n",
      "Gemini: Reply skipped due to word count limits.\n",
      "\n",
      "Gemini: Goodbye ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "# STEP 1: Setting the Gemini API key securely\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")  \n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# STEP 2: Creating the model\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# STEP 3: Initialize system prompt and history\n",
    "system_prompt = \"You are an intelligent assistant. Make sure you stay within 10 words.\"\n",
    "history = [f\"System: {system_prompt}\"]\n",
    "\n",
    "print(\"Type your messages. Type 'bye' to exit.\\n\")\n",
    "\n",
    "# STEP 4: Starting the chat loop",
    "while True:\n",
    "    user_msg = input(\"User: \").strip()\n",
    "\n",
    "    if not user_msg:\n",
    "        continue\n",
    "\n",
    "    if user_msg.lower() == \"bye\":\n",
    "        print(\"Gemini: Goodbye ðŸ‘‹\")\n",
    "        break\n",
    "\n",
    "    if user_msg.lower() == \"save\":\n",
    "        with open(\"conversation.txt\", \"w\") as file:\n",
    "            file.write(\"\\n\".join(history))\n",
    "        print(\"Conversation saved to conversation.txt\\n\")\n",
    "        continue\n",
    "\n",
    "    if user_msg.lower() == \"summary\":\n",
    "        summary_prompt = \"\\n\".join(history) + \"\\nUser: Summarize the conversation so far.\"\n",
    "        try:\n",
    "            response = model.generate_content(summary_prompt)\n",
    "            summary = response.text.strip()\n",
    "            print(f\"Gemini Summary: {summary}\\n\")\n",
    "        except Exception as e:\n",
    "            print(\"Summary failed:\", e)\n",
    "        continue\n",
    "\n",
    "    history.append(f\"User: {user_msg}\")\n",
    "    prompt = \"\\n\".join(history)\n",
    "\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            reply = response.text.strip()\n",
    "            word_count = len(reply.split())\n",
    "\n",
    "            if 15 <= word_count <= 50:\n",
    "                print(f\"Gemini: {reply}\\n\")\n",
    "                history.append(f\"Assistant: {reply}\")\n",
    "            else:\n",
    "                print(\"Gemini: Reply skipped due to word count limits.\\n\")\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed:\", e)\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"Gemini: Failed after 3 attempts. Exiting.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e94d7",
   "metadata": {},
   "source": [
    "## ANSWERS\n",
    "\n",
    "1 history.append(f\"User: {user_msg}\")\n",
    "\n",
    "2 model.generate_content(prompt)\n",
    "\n",
    "3 if not user_msg:\n",
    "        continue \n",
    "\n",
    "4 modify code so that more than 15 but less than 50\n",
    "word_count = len(reply.split())\n",
    "if 15 <= word_count <= 50:\n",
    "    ...\n",
    "else:\n",
    "    print(\"Gemini: Reply skipped due to word count limits.\\n\")\n",
    "\n",
    "5 saving info in txt file\n",
    "if user_msg.lower() == \"save\":\n",
    "    with open(\"conversation.txt\", \"w\") as file:\n",
    "        file.write(\"\\n\".join(history))\n",
    "\n",
    "6 error handling\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
